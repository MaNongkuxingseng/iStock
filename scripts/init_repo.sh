#!/bin/bash

# myStock-AI é¡¹ç›®åˆå§‹åŒ–è„šæœ¬
# ç”¨äºŽå¿«é€Ÿè®¾ç½®å¼€å‘çŽ¯å¢ƒå’ŒGitHubä»“åº“

set -e  # é‡åˆ°é”™è¯¯æ—¶é€€å‡º

echo "ðŸš€ å¼€å§‹åˆå§‹åŒ– myStock-AI é¡¹ç›®..."

# æ£€æŸ¥å¿…è¦å·¥å…·
echo "ðŸ”§ æ£€æŸ¥å¿…è¦å·¥å…·..."
command -v git >/dev/null 2>&1 || { echo "âŒ éœ€è¦å®‰è£… git"; exit 1; }
command -v docker >/dev/null 2>&1 || { echo "âŒ éœ€è¦å®‰è£… docker"; exit 1; }
command -v docker-compose >/dev/null 2>&1 || { echo "âŒ éœ€è¦å®‰è£… docker-compose"; exit 1; }

# åˆ›å»ºé¡¹ç›®ç›®å½•ç»“æž„
echo "ðŸ“ åˆ›å»ºé¡¹ç›®ç›®å½•ç»“æž„..."
mkdir -p src/{core,ml,web,utils}
mkdir -p data/{raw,processed,models}
mkdir -p docs/{api,architecture,deployment,user_guide}
mkdir -p tests/{unit,integration,e2e}
mkdir -p deployment/{docker,nginx,scripts}
mkdir -p .github/workflows
mkdir -p monitoring/{prometheus,grafana}

# åˆ›å»ºåŸºç¡€æ–‡ä»¶
echo "ðŸ“„ åˆ›å»ºåŸºç¡€é…ç½®æ–‡ä»¶..."

# Python çŽ¯å¢ƒé…ç½®
cat > .python-version << 'EOF'
3.10
EOF

cat > .env.example << 'EOF'
# æ•°æ®åº“é…ç½®
DATABASE_URL=postgresql://user:password@localhost:5432/mystock_ai
REDIS_URL=redis://localhost:6379/0

# API é…ç½®
API_HOST=0.0.0.0
API_PORT=8000
DEBUG=true

# æ•°æ®æºé…ç½®
SINA_API_URL=http://hq.sinajs.cn/list=
TENCENT_API_URL=http://qt.gtimg.cn/q=
EASTMONEY_API_URL=http://push2.eastmoney.com/api

# æœºå™¨å­¦ä¹ é…ç½®
ML_MODEL_PATH=./data/models
ML_TRAINING_DATA_PATH=./data/processed

# å‰ç«¯é…ç½®
VITE_API_URL=http://localhost:8000
VITE_APP_TITLE=myStock-AI

# ç›‘æŽ§é…ç½®
PROMETHEUS_URL=http://localhost:9090
GRAFANA_URL=http://localhost:3001
EOF

# Git é…ç½®
cat > .gitignore << 'EOF'
# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# Virtual Environments
venv/
env/
ENV/
env.bak/
venv.bak/

# IDE
.vscode/
.idea/
*.swp
*.swo
*~

# OS
.DS_Store
.DS_Store?
._*
.Spotlight-V100
.Trashes
ehthumbs.db
Thumbs.db

# Database
*.db
*.sqlite3

# Data
data/raw/
data/processed/
data/models/
!data/raw/.gitkeep
!data/processed/.gitkeep
!data/models/.gitkeep

# Logs
logs/
*.log

# Environment variables
.env
.env.local
.env.development.local
.env.test.local
.env.production.local

# Frontend
node_modules/
npm-debug.log*
yarn-debug.log*
yarn-error.log*
dist/
build/
.coverage
.nyc_output

# Coverage
.coverage
.coverage.*
.coverage*
htmlcov/

# Jupyter Notebook
.ipynb_checkpoints

# PyCharm
.idea/

# VS Code
.vscode/

# Docker
docker-compose.override.yml
EOF

# åˆ›å»ºå ä½æ–‡ä»¶
echo "ðŸ“ åˆ›å»ºå ä½æ–‡ä»¶..."
touch data/raw/.gitkeep
touch data/processed/.gitkeep
touch data/models/.gitkeep
touch src/core/__init__.py
touch src/ml/__init__.py
touch src/web/__init__.py
touch src/utils/__init__.py

# åˆ›å»ºåŸºç¡€ README
echo "ðŸ“– åˆ›å»ºåŸºç¡€æ–‡æ¡£..."
cat > docs/quickstart.md << 'EOF'
# å¿«é€Ÿå¼€å§‹æŒ‡å—

## çŽ¯å¢ƒè¦æ±‚

### ç³»ç»Ÿè¦æ±‚
- Python 3.10+
- Node.js 18+
- Docker 20.10+
- Docker Compose 2.0+

### å¼€å‘å·¥å…·
- Git
- VS Code æˆ– PyCharm
- PostgreSQL 14+ (å¯é€‰ï¼ŒDockerä¸­åŒ…å«)
- Redis 7+ (å¯é€‰ï¼ŒDockerä¸­åŒ…å«)

## æœ¬åœ°å¼€å‘è®¾ç½®

### 1. å…‹éš†ä»“åº“
```bash
git clone https://github.com/yourname/myStock-AI.git
cd myStock-AI
```

### 2. è®¾ç½®çŽ¯å¢ƒå˜é‡
```bash
cp .env.example .env
# ç¼–è¾‘ .env æ–‡ä»¶ï¼Œé…ç½®ä½ çš„è®¾ç½®
```

### 3. å¯åŠ¨å¼€å‘çŽ¯å¢ƒ
```bash
# ä½¿ç”¨ Docker Compose
docker-compose up -d

# æˆ–æ‰‹åŠ¨å¯åŠ¨å„ä¸ªæœåŠ¡
# å¯åŠ¨æ•°æ®åº“
docker-compose up -d postgres redis

# å¯åŠ¨åŽç«¯
cd backend
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
python src/main.py

# å¯åŠ¨å‰ç«¯
cd frontend
npm install
npm run dev
```

### 4. è®¿é—®åº”ç”¨
- å‰ç«¯: http://localhost:3000
- åŽç«¯API: http://localhost:8000
- APIæ–‡æ¡£: http://localhost:8000/docs
- ç›‘æŽ§é¢æ¿: http://localhost:3001 (ç”¨æˆ·å: admin, å¯†ç : admin)

## å¼€å‘å·¥ä½œæµ

### ä»£ç è§„èŒƒ
```bash
# ä»£ç æ ¼å¼åŒ–
black src/
isort src/

# ä»£ç æ£€æŸ¥
flake8 src/
mypy src/

# è¿è¡Œæµ‹è¯•
pytest tests/
```

### Git å·¥ä½œæµ
1. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯: `git checkout -b feature/your-feature`
2. å¼€å‘å¹¶æäº¤: `git add . && git commit -m "feat: add your feature"`
3. æŽ¨é€åˆ°è¿œç¨‹: `git push origin feature/your-feature`
4. åˆ›å»º Pull Request

## å¸¸è§é—®é¢˜

### æ•°æ®åº“è¿žæŽ¥é—®é¢˜
```bash
# æ£€æŸ¥æ•°æ®åº“çŠ¶æ€
docker-compose ps

# æŸ¥çœ‹æ•°æ®åº“æ—¥å¿—
docker-compose logs postgres

# é‡ç½®æ•°æ®åº“
docker-compose down -v
docker-compose up -d
```

### å‰ç«¯æž„å»ºé—®é¢˜
```bash
# æ¸…ç†ç¼“å­˜
rm -rf node_modules
npm cache clean --force
npm install
```

### åŽç«¯ä¾èµ–é—®é¢˜
```bash
# é‡æ–°åˆ›å»ºè™šæ‹ŸçŽ¯å¢ƒ
rm -rf venv
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

## èŽ·å–å¸®åŠ©

- æŸ¥çœ‹è¯¦ç»†æ–‡æ¡£: `docs/` ç›®å½•
- æŠ¥å‘Šé—®é¢˜: GitHub Issues
- è®¨è®ºåŠŸèƒ½: GitHub Discussions
EOF

# åˆ›å»º Docker åŸºç¡€æ–‡ä»¶
echo "ðŸ³ åˆ›å»º Docker é…ç½®æ–‡ä»¶..."

# åŽç«¯ Dockerfile
cat > backend/Dockerfile << 'EOF'
FROM python:3.10-slim

WORKDIR /app

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    postgresql-client \
    && rm -rf /var/lib/apt/lists/*

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY requirements.txt .

# å®‰è£… Python ä¾èµ–
RUN pip install --no-cache-dir -r requirements.txt

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY . .

# åˆ›å»ºéž root ç”¨æˆ·
RUN useradd -m -u 1000 appuser && chown -R appuser:appuser /app
USER appuser

# è¿è¡Œåº”ç”¨
CMD ["uvicorn", "src.main:app", "--host", "0.0.0.0", "--port", "8000"]
EOF

# å‰ç«¯ Dockerfile
cat > frontend/Dockerfile << 'EOF'
FROM node:18-alpine as builder

WORKDIR /app

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY package*.json ./

# å®‰è£…ä¾èµ–
RUN npm ci --only=production

# å¤åˆ¶æºä»£ç 
COPY . .

# æž„å»ºåº”ç”¨
RUN npm run build

# ç”Ÿäº§çŽ¯å¢ƒ
FROM nginx:alpine

# å¤åˆ¶æž„å»ºæ–‡ä»¶
COPY --from=builder /app/dist /usr/share/nginx/html

# å¤åˆ¶ nginx é…ç½®
COPY nginx.conf /etc/nginx/conf.d/default.conf

EXPOSE 80

CMD ["nginx", "-g", "daemon off;"]
EOF

# åˆ›å»º requirements.txt
cat > backend/requirements.txt << 'EOF'
# åŸºç¡€ä¾èµ–
fastapi==0.104.1
uvicorn[standard]==0.24.0
python-multipart==0.0.6

# æ•°æ®åº“
sqlalchemy==2.0.23
alembic==1.12.1
psycopg2-binary==2.9.9
asyncpg==0.29.0

# ç¼“å­˜å’Œæ¶ˆæ¯é˜Ÿåˆ—
redis==5.0.1
celery==5.3.4

# æ•°æ®å¤„ç†
pandas==2.1.4
numpy==1.26.2
scipy==1.11.4

# æœºå™¨å­¦ä¹ 
scikit-learn==1.3.2
torch==2.1.1
torchvision==0.16.1
xgboost==2.0.2

# æŠ€æœ¯æŒ‡æ ‡
TA-Lib==0.4.28

# HTTP å®¢æˆ·ç«¯
httpx==0.25.1
aiohttp==3.9.1
requests==2.31.0

# å·¥å…·åº“
python-dotenv==1.0.0
pydantic==2.5.0
pydantic-settings==2.1.0
loguru==0.7.2

# æµ‹è¯•
pytest==7.4.3
pytest-asyncio==0.21.1
pytest-cov==4.1.0

# å¼€å‘å·¥å…·
black==23.11.0
isort==5.12.0
flake8==6.1.0
mypy==1.7.0
pre-commit==3.5.0
EOF

# åˆ›å»º package.json
cat > frontend/package.json << 'EOF'
{
  "name": "mystock-ai-frontend",
  "version": "1.0.0",
  "private": true,
  "scripts": {
    "dev": "vite",
    "build": "tsc && vite build",
    "preview": "vite preview",
    "lint": "eslint . --ext ts,tsx --report-unused-disable-directives --max-warnings 0",
    "format": "prettier --write .",
    "test": "jest"
  },
  "dependencies": {
    "react": "^18.2.0",
    "react-dom": "^18.2.0",
    "react-router-dom": "^6.20.0",
    "antd": "^5.12.2",
    "@ant-design/icons": "^5.2.6",
    "@ant-design/charts": "^2.0.2",
    "axios": "^1.6.2",
    "zustand": "^4.4.7",
    "dayjs": "^1.11.10",
    "lodash": "^4.17.21"
  },
  "devDependencies": {
    "@types/react": "^18.2.37",
    "@types/react-dom": "^18.2.15",
    "@typescript-eslint/eslint-plugin": "^6.13.2",
    "@typescript-eslint/parser": "^6.13.2",
    "@vitejs/plugin-react": "^4.2.0",
    "eslint": "^8.55.0",
    "eslint-plugin-react-hooks": "^4.6.0",
    "eslint-plugin-react-refresh": "^0.4.5",
    "jest": "^29.7.0",
    "prettier": "^3.1.0",
    "typescript": "^5.2.2",
    "vite": "^5.0.0"
  }
}
EOF

# åˆ›å»ºæ•°æ®åº“åˆå§‹åŒ–è„šæœ¬
cat > scripts/init-db.sql << 'EOF'
-- åˆ›å»ºæ‰©å±•
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";

-- åˆ›å»ºè‚¡ç¥¨åŸºæœ¬ä¿¡æ¯è¡¨
CREATE TABLE stocks (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    code VARCHAR(10) NOT NULL UNIQUE,
    name VARCHAR(100) NOT NULL,
    market VARCHAR(10),
    industry VARCHAR(100),
    listing_date DATE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- åˆ›å»ºè‚¡ç¥¨æ—¥çº¿æ•°æ®è¡¨
CREATE TABLE stock_daily (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    stock_id UUID REFERENCES stocks(id) ON DELETE CASCADE,
    date DATE NOT NULL,
    open DECIMAL(10, 3),
    high DECIMAL(10, 3),
    low DECIMAL(10, 3),
    close DECIMAL(10, 3),
    volume BIGINT,
    amount DECIMAL(20, 3),
    change DECIMAL(10, 3),
    change_percent DECIMAL(10, 3),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(stock_id, date)
);

-- åˆ›å»ºæŠ€æœ¯æŒ‡æ ‡è¡¨
CREATE TABLE technical_indicators (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    stock_id UUID REFERENCES stocks(id) ON DELETE CASCADE,
    date DATE NOT NULL,
    ma5 DECIMAL(10, 3),
    ma10 DECIMAL(10, 3),
    ma20 DECIMAL(10, 3),
    ma60 DECIMAL(10, 3),
    rsi DECIMAL(10, 3),
    macd DECIMAL(10, 3),
    macd_signal DECIMAL(10, 3),
    macd_hist DECIMAL(10, 3),
    kdj_k DECIMAL(10, 3),
    kdj_d DECIMAL(10, 3),
    kdj_j DECIMAL(10, 3),
    boll_upper DECIMAL(10, 3),
    boll_middle DECIMAL(10, 3),
    boll_lower DECIMAL(10, 3),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(stock_id, date)
);

-- åˆ›å»ºæœºå™¨å­¦ä¹ é¢„æµ‹è¡¨
CREATE TABLE ml_predictions (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    stock_id UUID REFERENCES stocks(id) ON DELETE CASCADE,
    date DATE NOT NULL,
    model_name VARCHAR(100),
    prediction_type VARCHAR(50),
    predicted_value DECIMAL(10, 3),
    confidence DECIMAL(5, 3),
    features JSONB,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(stock_id, date, model_name, prediction_type)
);

-- åˆ›å»ºç”¨æˆ·æŒä»“è¡¨
CREATE TABLE user_positions (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    user_id UUID NOT NULL,
    stock_id UUID REFERENCES stocks(id) ON DELETE CASCADE,
    shares INTEGER NOT NULL,
    cost_price DECIMAL(10, 3) NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(user_id, stock_id)
);

-- åˆ›å»ºæ•°æ®è´¨é‡ç›‘æŽ§è¡¨
CREATE TABLE data_quality (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    data_source VARCHAR(50),
    data_type VARCHAR(50),
    check_time TIMESTAMP NOT NULL,
    completeness_score DECIMAL(5, 3),
    accuracy_score DECIMAL(5, 3),
    timeliness_score DECIMAL(5, 3),
    issues JSONB,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- åˆ›å»ºç´¢å¼•
CREATE INDEX idx_stock_daily_stock_id ON stock_daily(stock_id);
CREATE INDEX idx_stock_daily_date ON stock_daily(date);
CREATE INDEX idx_technical_indicators_stock_id ON technical_indicators(stock_id);
CREATE INDEX idx_technical_indicators_date ON technical_indicators(date);
CREATE INDEX idx_ml_predictions_stock_id ON ml_predictions(stock_id);
CREATE INDEX idx_ml_predictions_date ON ml_predictions(date);
CREATE INDEX idx_user_positions_user_id ON user_positions(user_id);
CREATE INDEX idx_data_quality_check_time ON data_quality(check_time);

-- åˆ›å»ºæ›´æ–°æ—¶é—´çš„è§¦å‘å™¨å‡½æ•°
CREATE OR REPLACE FUNCTION update_updated_at_column()
RETURNS TRIGGER AS $$
BEGIN
    NEW.updated_at = CURRENT_TIMESTAMP;
    RETURN NEW;
END;
$$ language 'plpgsql';

-- ä¸ºéœ€è¦æ›´æ–°æ—¶é—´çš„è¡¨æ·»åŠ è§¦å‘å™¨
CREATE TRIGGER update_stocks_updated_at BEFORE UPDATE ON stocks
    FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();

CREATE TRIGGER update_user_positions_updated_at BEFORE UPDATE ON user_positions
    FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();
EOF

echo "âœ… é¡¹ç›®ç»“æž„åˆ›å»ºå®Œæˆï¼"
echo ""
echo "ðŸ“‹ ä¸‹ä¸€æ­¥æ“ä½œï¼š"
echo "1. åˆå§‹åŒ– Git ä»“åº“:"
echo "   git init"
echo "   git add ."
echo "   git commit -m 'feat: initial project structure'"
echo ""
echo "2. è¿žæŽ¥åˆ° GitHub:"
echo "   git remote add origin https://github.com/YOUR_USERNAME/myStock-AI.git"
echo "   git push -u origin main"
echo ""
echo "3. è®¾ç½®å¼€å‘çŽ¯å¢ƒ:"
echo "   cp .env.example .env"
echo "   # ç¼–è¾‘ .env æ–‡ä»¶é…ç½®ä½ çš„è®¾ç½®"
echo ""
echo "4. å¯åŠ¨å¼€å‘çŽ¯å¢ƒ:"
echo "   docker-compose up -d"
echo ""
echo "ðŸŽ‰ é¡¹ç›®åˆå§‹åŒ–å®Œæˆï¼å¼€å§‹å¼€å‘å§ï¼"